#!/usr/bin/env python

import os
import numpy as np
import torch
from gradslam.slam.pointfusion import PointFusion
from gradslam.slam.icpslam import ICPSLAM
from gradslam import Pointclouds, RGBDImages
from supervised_depth_correction.data import Dataset
from supervised_depth_correction.utils import load_model
# ROS
import rospy
from sensor_msgs.msg import CameraInfo, PointCloud2
from nav_msgs.msg import Path
from geometry_msgs.msg import PoseStamped, TransformStamped
from ros_numpy import msgify
from tf.transformations import quaternion_from_matrix
import tf2_ros


def publish_tf_pose(pose, child_frame_id):
    assert isinstance(pose, PoseStamped)
    br = tf2_ros.TransformBroadcaster()
    t = TransformStamped()
    t.header.stamp = pose.header.stamp
    t.header.frame_id = pose.header.frame_id
    t.child_frame_id = child_frame_id
    t.transform.translation.x = pose.pose.position.x
    t.transform.translation.y = pose.pose.position.y
    t.transform.translation.z = pose.pose.position.z
    t.transform.rotation.x = pose.pose.orientation.x
    t.transform.rotation.y = pose.pose.orientation.y
    t.transform.rotation.z = pose.pose.orientation.z
    t.transform.rotation.w = pose.pose.orientation.w
    br.sendTransform(t)


def matrix_to_pose_msg(T, frame_id='world'):
    assert T.shape == (4, 4)
    pose = PoseStamped()
    pose.header.frame_id = frame_id
    pose.header.stamp = rospy.Time.now()
    pose.pose.position.x = T[0, 3]
    pose.pose.position.y = T[1, 3]
    pose.pose.position.z = T[2, 3]
    q = quaternion_from_matrix(T)
    pose.pose.orientation.x = q[0]
    pose.pose.orientation.y = q[1]
    pose.pose.orientation.z = q[2]
    pose.pose.orientation.w = q[3]
    return pose


class GradslamROS:
    def __init__(self, subseq: str = ''):
        self.device = torch.device(rospy.get_param('~device', 'cuda:0'))
        # self.slam = PointFusion(odom=rospy.get_param('~odometry', 'gt'), dsratio=1, device=self.device)
        self.slam = ICPSLAM(odom=rospy.get_param('~odometry', 'gt'), dsratio=1, device=self.device)
        self.pointclouds = Pointclouds(device=self.device)
        self.live_frame = None
        self.route = Path()
        self.world_frame = 'world'
        self.camera_frame = 'camera'
        self.route.header.frame_id = self.world_frame
        self.route_pub = rospy.Publisher('~route', Path, queue_size=2)
        self.pc_pub = rospy.Publisher('~cloud', PointCloud2, queue_size=1)
        self.caminfo_pub = rospy.Publisher('~frustum', CameraInfo, queue_size=1)
        self.map_step = rospy.get_param('~map_step', 4)
        self.camera = rospy.get_param('~camera', 'left')  # 'right', 'left'
        self.ds = Dataset(subseq, gt=rospy.get_param('~gt_depth', False), camera=self.camera, zero_origin=False)
        self.delay_start = rospy.get_param('~delay_start', 1.0)
        self.period = rospy.get_param('~period', 1.0)
        self.index = 0
        self.ds_step = 1
        self.device = torch.device(rospy.get_param('~device', 'cpu'))
        self.depth_completion = rospy.get_param('~depth_completion', False)
        self.dc_model = load_model(rospy.get_param('~dc_model_path',
                                                   os.path.realpath(os.path.join(os.path.dirname(__file__), '../config/results/weights/weights-539.pth'))))
        self.dc_model.to(self.device)
        self.dc_model.eval()
        self.timer = rospy.Timer(rospy.Duration(self.delay_start), self.start_timer, oneshot=True)

    def start_timer(self, evt):
        self.timer = rospy.Timer(rospy.Duration(self.period), self.run)
        rospy.loginfo('Publishing robot data.')

    def move(self):
        if self.index < len(self.ds):
            self.index += 1
            rospy.logdebug('Moved to next data sample')

    def slam_step(self):
        colors, depths, intrinsics, poses = self.ds[self.index * self.ds_step]
        colors = colors.to(self.device)
        depths = depths.to(self.device)
        intrinsics = intrinsics.to(self.device)
        poses = poses.to(self.device)

        # depth completion model forward pass
        if self.dc_model is not None and self.depth_completion:
            rospy.loginfo('Applying depth completion model')
            with torch.no_grad():
                depths = self.dc_model(depths, mask=(depths > 0).float())

        live_frame = RGBDImages(colors, depths, intrinsics, poses)
        self.pointclouds, live_frame.poses = self.slam.step(self.pointclouds, live_frame, self.live_frame)

        self.live_frame = live_frame
        rospy.logdebug(f'Point cloud shape: {self.pointclouds.points_list[0].shape}')

    def run(self, evt):
        self.slam_step()
        self.publish_path()
        self.publish_cloud()
        # self.publish_camera_info()
        self.move()

    def publish_camera_info(self, distortion_model="plumb_bob"):
        camera_info = CameraInfo()
        camera_info.header.frame_id = self.camera_frame
        camera_info.header.stamp = rospy.Time.now()
        camera_info.width = self.live_frame.rgb_image.shape[-2]
        camera_info.height = self.live_frame.rgb_image.shape[-3]
        camera_info.K = self.live_frame.intrinsics.squeeze()[:3, :3].cpu().numpy().flatten().tolist()
        camera_info.distortion_model = distortion_model
        self.caminfo_pub.publish(camera_info)
        return camera_info

    def publish_path(self):
        assert self.live_frame.poses.shape == (1, 1, 4, 4)
        pose = matrix_to_pose_msg(self.live_frame.poses.squeeze().cpu().numpy())
        publish_tf_pose(pose, child_frame_id=self.camera_frame)
        self.route.poses.append(pose)
        self.route.header.stamp = rospy.Time.now()
        self.route_pub.publish(self.route)
        rospy.logdebug('Published path')

    def publish_cloud(self):
        # publish point cloud
        n_pts = np.ceil(self.pointclouds.points_padded.shape[1] / self.map_step).astype(int)
        cloud = np.zeros((n_pts,), dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'),
                                          ('r', 'f4'), ('g', 'f4'), ('b', 'f4')])
        for i, f in enumerate(['x', 'y', 'z']):
            cloud[f] = self.pointclouds.points_padded[..., i].detach().squeeze().cpu().numpy()[::self.map_step]
        for i, f in enumerate(['r', 'g', 'b']):
            cloud[f] = self.pointclouds.colors_padded[..., i].detach().squeeze().cpu().numpy()[::self.map_step] / 255.
        pc_msg = msgify(PointCloud2, cloud)
        pc_msg.header.stamp = rospy.Time.now()
        pc_msg.header.frame_id = self.world_frame
        self.pc_pub.publish(pc_msg)
        rospy.logdebug('Published point cloud')


def main():
    rospy.init_node('supervised_depth_correction_ros', log_level=rospy.DEBUG)
    subseqs = [
        "2011_09_26_drive_0001_sync",
        "2011_09_26_drive_0009_sync",
        "2011_09_26_drive_0011_sync",
        "2011_09_26_drive_0018_sync",
        "2011_09_30_drive_0016_sync"
    ]
    # subseq = np.random.choice(subseqs, 1)[0]
    subseq = rospy.get_param('~kitti_sequence', subseqs[1])
    proc = GradslamROS(subseq)
    rospy.spin()


if __name__ == '__main__':
    main()
